{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!pyspark --packages com.amazonaws:aws-java-sdk-pom:1.10.34,org.apache.hadoop:hadoop-aws:2.7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import pyspark\n",
    "import configparser\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dl.cfg'))\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']\n",
    "#os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.amazonaws:aws-java-sdk-pom:1.10.34,org.apache.hadoop:hadoop-aws:2.7.2 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws-cli/1.16.17 Python/3.6.3 Linux/4.15.0-1083-gcp botocore/1.12.7\n"
     ]
    }
   ],
   "source": [
    "!aws --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "SparkSession - in-memory\n",
    "SparkContext\n",
    "Spark UI\n",
    "Version\n",
    "    v2.4.3\n",
    "Master\n",
    "    local[*]\n",
    "AppName\n",
    "    pyspark-shell\n",
    "'''\n",
    "spark = SparkSession.builder\\\n",
    "                     .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "                     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.32 ms, sys: 502 µs, total: 8.82 ms\n",
      "Wall time: 38.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_events_raw = spark.read.json(\"s3a://udacity-dend/log_data/2018/11/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def transform_events(df_events_raw):\n",
    "    df_events = df_events_raw.filter(F.col('page')=='NextSong') # df_events.count() = 6820\n",
    "    ts_transform = F.to_timestamp(F.from_unixtime(F.col(\"ts\")/1000,'yyyy-MM-dd HH:mm:ss'))\n",
    "\n",
    "    dt = df_events.withColumn(\"start_time\", ts_transform)\\\n",
    "    .withColumn(\"hour\",F.hour(ts_transform))\\\n",
    "    .withColumn(\"day\",F.dayofmonth(ts_transform))\\\n",
    "    .withColumn(\"week\",F.weekofyear(ts_transform))\\\n",
    "    .withColumn(\"month\",F.month(ts_transform))\\\n",
    "    .withColumn(\"year\",F.year(ts_transform))\\\n",
    "    .withColumn(\"weekday\",F.date_format(ts_transform, \"EEEE\"))\n",
    "    \n",
    "    users_cols =[\"userId\", \"firstName\", \"lastName\", \"gender\", \"level\",\"sessionId\"]\n",
    "    users_cols_new_names = [\"user_id\", \"first_name\", \"last_name\", \"gender\", \"level\",\"session_id\"]\n",
    "    name_mapping = dict(zip(users_cols, users_cols_new_names))\n",
    "\n",
    "    time_cols = [\"start_time\", \"hour\", \"day\", \"week\", \"month\", \"year\", \"weekday\"]\n",
    "    time_df_ = dt.select(*time_cols)\n",
    "    time_df = time_df_.distinct() # 6813\n",
    "\n",
    "    users_df_ = dt.select(*users_cols)\n",
    "    users_df_ = users_df_.select([F.col(c).alias(name_mapping.get(c, c)) for c in users_df_.columns])\n",
    "    users_df = users_df_.distinct() # 784\n",
    "    \n",
    "    songplays_proto_cols = [\"song\", \"artist\", \"start_time\",\"userId\",\"level\", \"sessionId\", \"location\", \"userAgent\"]\n",
    "    songplays_proto_cols_new = [\"song\", \"artist\", \"start_time\", \"user_id\", \"level\", \"session_id\", \"location\", \"user_agent\"]\n",
    "    name_mapping2 = dict(zip(songplays_proto_cols, songplays_proto_cols_new))\n",
    "    \n",
    "    songplays_proto_df_ = dt.select(*songplays_proto_cols)\n",
    "    songplays_proto_df = songplays_proto_df_.select([F.col(c).alias(name_mapping2.get(c, c)) for c in songplays_proto_df_.columns])\n",
    "    \n",
    "    return time_df, users_df, songplays_proto_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.4 ms, sys: 5.03 ms, total: 40.4 ms\n",
      "Wall time: 1.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "time_df, users_df, songplays_proto_df = transform_events(df_events_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-03 18:03:41 aws-emr-resources-365869683794-us-east-2\n",
      "2021-05-17 13:37:25 course-data-lake-proj\n",
      "2021-05-17 13:41:04 course-datalake-prj\n",
      "2021-04-01 15:16:17 my-dataengaws-course-bucket\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls\n",
    "!aws configure get region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE bootstrap/\n",
      "                           PRE emr-logs/\n",
      "                           PRE log_data/\n",
      "                           PRE song_data/\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://course-datalake-prj/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#arn:aws:s3:::aws-emr-resources-365869683794-us-east-2\n",
    "#s3://my-dataengaws-course-bucket/bootstraps/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.4 ms, sys: 3.51 ms, total: 42 ms\n",
      "Wall time: 3min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "CPU times: user 38.2 ms, sys: 3.47 ms, total: 41.7 ms\n",
    "Wall time: 3min 44s\n",
    "'''\n",
    "# does NOT work............\n",
    "#df_songs_raw = spark.read.json(\"s3a://udacity-dend/song_data/A/*/*/*.json\") takes too long time to execute\n",
    "#df_songs_raw = spark.sparkContext.broadcast(spark.read.json(\"s3a://udacity-dend/song_data/A/B/*/*.json\"))\n",
    "\n",
    "#df_songs_raw = spark.read.json(\"s3a://course-datalake-prj/song_data/A/A/*/*.json\")# 604\n",
    "\n",
    "#https://course-datalake-prj.s3.us-east-2.amazonaws.com/song_data/A/A/A/TRAAAAK128F9318786.json\n",
    "#s3://course-datalake-prj/song_data/A/A/A/\n",
    "df_songs_raw = spark.read.json(\"s3a://udacity-dend/song_data/A/A/*/*.json\")# 604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def transform_songs(df_songs_raw):\n",
    "\n",
    "    songs_cols = [\"song_id\", \"title\", \"artist_id\", \"year\", \"duration\"]\n",
    "    songs_df_ = df_songs_raw.select(*songs_cols)\n",
    "    songs_df = songs_df_.distinct() # in the subset 604\n",
    "\n",
    "    artists_cols = [\"artist_id\", \"artist_name\", \"artist_location\", \"artist_latitude\", \"artist_longitude\"]\n",
    "    artists_cols_new = [\"artist_id\", \"name\", \"location\", \"lattitude\", \"longitude\"]\n",
    "\n",
    "    name_mapping = dict(zip(artists_cols, artists_cols_new))\n",
    "    artists_df_ = df_songs_raw.select(*artists_cols)\n",
    "    artists_df_ = artists_df_.select([F.col(c).alias(name_mapping.get(c, c)) for c in artists_df_.columns])\n",
    "    artists_df = artists_df_.distinct() # in the subset 591\n",
    "\n",
    "    songplays_proto2_cols = [\"artist_name\", \"title\", \"artist_id\", \"song_id\"]\n",
    "\n",
    "    songplays_proto2_df_ = df_songs_raw.select(*songplays_proto2_cols)\n",
    "    songplays_proto2_df = songplays_proto2_df_.distinct() # in the subset 604\n",
    "    return songs_df, artists_df, songplays_proto2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.2 ms, sys: 741 µs, total: 15 ms\n",
      "Wall time: 160 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "songs_df, artists_df, songplays_proto2_df = transform_songs(df_songs_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "joined_df = songplays_proto_df.join(songplays_proto2_df).where(songplays_proto_df.song.eqNullSafe(songplays_proto2_df.title))\\\n",
    ".where(songplays_proto_df.artist.eqNullSafe(songplays_proto2_df.artist_name)) # in the subset 16\n",
    "\n",
    "joined_dfp = joined_df.withColumn(\"songplay_id\", F.monotonically_increasing_id())\n",
    "\n",
    "songplays_cols = [\"songplay_id\", \"start_time\", \"user_id\", \"level\", \"song_id\", \"artist_id\", \"session_id\", \"location\", \"user_agent\"]\n",
    "songplays_df = joined_dfp.select(*songplays_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent\n",
    "#joined_dfp.limit(5).toPandas()\n",
    "#joined_dfp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df.write.partitionBy(\"year\",\"month\").mode(\"overwrite\").parquet(\"/tmp/output/songplays.parquet\")\n",
    "songplays_df = songplays_df.withColumn(\"year\", F.year(\"start_time\"))\\\n",
    ".withColumn(\"month\", F.month(\"start_time\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songplays_df.write.partitionBy(\"year\", \"month\").mode(\"overwrite\").parquet(\n",
    "    \"/home/workspace/analytics/songplays/songplays.parquet\")\n",
    "\n",
    "songs_df.write.partitionBy(\"year\", \"artist_id\").mode(\"overwrite\").parquet(\n",
    "    \"/home/workspace/analytics/songs/songs.parquet\")\n",
    "\n",
    "time_df.write.partitionBy(\"year\", \"month\").mode(\"overwrite\").parquet(\n",
    "    \"/home/workspace/analytics/time/time.parquet\")\n",
    "\n",
    "users_df.write.mode(\"overwrite\").parquet(\n",
    "    \"/home/workspace/analytics/users/users.parquet\")\n",
    "\n",
    "artists_df.write.mode(\"overwrite\").parquet(\n",
    "    \"/home/workspace/analytics/artists/artists.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!aws s3 cp /home/workspace/analytics/ s3://course-datalake-prj/analytics/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
